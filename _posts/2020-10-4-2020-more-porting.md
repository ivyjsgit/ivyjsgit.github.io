---
layout: post
title: More Porting, Swift and iOS development!
categories: [general]
tags: [disco-tray-studios, senior-seminar, manuscript]
fullview: true
comments: true
---

### More Porting!

My work this week at Disco Tray Studios served as continuation of last week's work of porting existing PHP and Javascript code to the ASP.NET framework. 

### iOS Development and Senior Seminar

In Senior Seminar, I needed to (mostly) completely restart on my [Manuscript](https://github.com/ivyjsgit/manuscript) project, as both TensorFlow and Android Studio were both proving to be much more complicated systems than I initially believed. 

TensorFlow was a board with billions of confusing knobs, and each time I turned one of them, my results would drastically change. I was getting strange results such as my models only predicting 1 class or extremely high overfitting, and between changing my preprocessing, adjusting my layers, activation functions, and loss functions, I was completely at a loss. 

I decided to set this aside for a moment and work on the Android app side of things.

Problems quickly arose. In order to draw a picture of a symbol that I created in Lightroom, I needed to first create a Drawable of the image file. This makes sense. 

Next, you must place this Drawable on a Canvas. Rather than a Canvas being something that you can create in the Layout Editor, you must create a class that extends View, override onDraw(), and make Canvas as a parameter.

<iframe width="720" height="480" src="https://www.youtube.com/embed/QwucZK1BCj4" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

Because of this, I decided to switch my project back to my original plan of an iOS app. After I installed Xcode and began doing research into CoreML, I was surprised to learn that you did not need a developer license to use Apple's machine learning toolkit. 

Training my new model was extremely easy compared to TensorFlow, as CoreML does most of the tweaking for you. Even though my overall accuracy was lower (~76%) than TensorFlow, I did not get the pesky single-class prediction issues or signs of overfitting such as failing to recognize symbols from outside of the dataset. Overall, I see this as a net positive, as I don't think I could have fixed even with all of the capabilities of TensorFlow, just because I didn't know enough about it. 

Creating the UI itself was easy through the use of SwiftUI, though I'm still having issues with sizing on different devices.

Here's my progress as viewed on an iPad Pro 12.9" simulator:

![Actual timeline]({{site.baseurl}}/assets/media/manuscript-screenshot.png)
